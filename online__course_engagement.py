# -*- coding: utf-8 -*-
"""ONLINE _COURSE_ENGAGEMENT.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1Mwgogi9Upd-nuu2iHAbDSdMM8YsEijxH

**INTRODUCTION TO THE PROJECT**

**The main objective of this project is to predict whether the user has completed his/her course based on the features provided.**


This dataset captures user engagement metrics from an online course platform, facilitating analyses on factors influencing course completion. It includes user demographics, course-specific data, and engagement metrics.

**Features:**

**UserID**: Unique identifier for each user

**CourseCategory**: Category of the course taken by the user (e.g., Programming, Business, Arts)

**TimeSpentOnCourse**: Total time spent by the user on the course in hours

**NumberOfVideosWatched**: Total number of videos watched by the user

**NumberOfQuizzesTaken**: Total number of quizzes taken by the user

**QuizScores**: Average scores achieved by the user in quizzes (percentage)

**CompletionRate**: Percentage of course content completed by the user

**DeviceType**: Type of device used by the user (Device Type: Desktop (0) or Mobile (1))

**CourseCompletion** (Target Variable):

Course completion status (0: Not Completed, 1: Completed)

**TO PERMIT OUR COLAB NOTEBOOK TO ACCESS THE FILES PRESENT IN THE GOOGLE DRIVE**
"""

from google.colab import drive
drive.mount('/content/gdrive')

"""**IMPORTING ALL THE NECESSARY LIBRARIES**"""

import pandas as pd
import numpy as np
import matplotlib.pyplot as plt
import seaborn as sns
import plotly.express as px
df=pd.read_csv('/content/online_course_engagement_data.csv')
df

"""**EDA(EXPLORATORY DATA ANALYSIS)**

Basic Exploratory Data Analysis (EDA) in machine learning involves the following key steps:

**Understanding the Data:**

Examine the dataset's structure, dimensions, and general information. Check the data types of each feature (numeric, categorical, etc.). Verify if there are any missing values in the dataset.

**Descriptive Statistics:**

Calculate basic summary statistics (mean, median, mode, standard deviation, etc.) for numerical features. Explore the distribution of the target variable.

**Univariate Analysis: **

Analyze individual features in isolation to understand their characteristics. Create histograms, box plots, or frequency distributions for numerical features. Use bar plots for categorical features to visualize their distribution.

**Bivariate Analysis:**

Explore relationships between pairs of features. Use scatter plots for numerical features to identify patterns or correlations. Utilize correlation matrices to quantify the degree of correlation between variables.

**Handling Outliers:**

Identify and examine outliers in the dataset. Decide whether to remove or transform outliers based on domain knowledge and the impact on the model.

**Handling Missing Data:**

Assess the extent of missing values in the dataset. Decide on a strategy to handle missing data (imputation, removal, etc.).

**Feature Engineering:**

Create new features that might enhance the model's predictive power. Convert categorical variables into numerical representations through encoding techniques.

**Data Visualization:**

Use visualizations such as heatmaps, pair plots, or correlation plots to gain insights into the relationships between multiple variables. Addressing Data Imbalances (if applicable):

Check for class imbalances, especially in classification problems, and decide on strategies for handling them.

**Preparing Data for Modeling:**

Split the dataset into training and testing sets. Normalize or standardize numerical features if needed. A thorough EDA provides valuable insights into the characteristics of the data, helping in better feature selection, preprocessing, and ultimately improving the performance of machine learning models.
"""

df.shape

df.size

df.head()

df.describe()

df.dtypes

"""**REMOVING UNWANTED COLUMNS**


"""

df.pop('UserID')

df

"""**CHECKING FOR THE MISSING VALUES**"""

df.isnull().sum()

sns.barplot(x=df['CourseCategory'],y=df['NumberOfVideosWatched'],color='yellow')

px.pie(df,names='CourseCategory')

df.columns

sns.barplot(x=df['DeviceType'],y=df['NumberOfVideosWatched'],color='orange')

sns.histplot(x=df['DeviceType'],color='red')

sns.histplot(df['CourseCompletion'],color='blue')

sns.barplot(x=df['CourseCategory'],y=df['NumberOfQuizzesTaken'],color='pink',hue=df['DeviceType'])

plt.figure(figsize=(10,10))
sns.heatmap(df.corr(),annot=True, cmap='coolwarm', fmt='.2f', linewidths=1, linecolor= 'black')
plt.title('Correlation Heatmap')
plt.show()

sns.scatterplot(x='QuizScores',y='CompletionRate',data=df,hue ='CourseCompletion')
plt.show()

"""**CONVERTING CATEGORICAL DATA INTO NUMERICAL DATA**"""

from sklearn.preprocessing import LabelEncoder
le=LabelEncoder()
df['CourseCategory']=le.fit_transform(df['CourseCategory'])
df

"""**SPLITTING THE DATA**"""

x=df[['CourseCategory','TimeSpentOnCourse','NumberOfVideosWatched','NumberOfQuizzesTaken','QuizScores','CompletionRate','DeviceType'	]]
y=df['CourseCompletion']
from sklearn.model_selection import train_test_split
x_train,x_test,y_train,y_test=train_test_split(x,y,test_size=0.20)
print(x_train.shape)
print(x_test.shape)

"""**SCALING THE DATA**"""

from sklearn.preprocessing import StandardScaler
sc=StandardScaler()
x_train_scaled=sc.fit_transform(x_train)
x_test_scaled=sc.transform(x_test)
print(x_train_scaled)
print(x_test_scaled)

"""**CREATING MODELS**

**MODEL 1: LOGISTIC REGRESSION**
"""

from sklearn.linear_model import LogisticRegression
lr=LogisticRegression()
lr.fit(x_train_scaled,y_train)

pred1=lr.predict(x_test_scaled)
pred1

from sklearn.metrics import confusion_matrix
cm=confusion_matrix(y_test,pred1)
cm

from sklearn.metrics import accuracy_score
accuracy_score(y_test,pred1)

"""**MODEL 2: DECISION TREE CLASSIFIER**"""

from sklearn.tree import DecisionTreeClassifier
dt=DecisionTreeClassifier()
dt.fit(x_train_scaled,y_train)

pred2=dt.predict(x_test_scaled)
pred2

from sklearn.metrics import accuracy_score
accuracy_score(y_test,pred2)

"""**MODEL 3: RANDOM FOREST CLASSIFIER**"""

from sklearn.ensemble import RandomForestClassifier
rf=RandomForestClassifier()
rf.fit(x_train_scaled,y_train)

pred3=rf.predict(x_test_scaled)
pred3

from sklearn.metrics import accuracy_score
accuracy_score(y_test,pred3)

"""**MODEL 4: K NEAREST NEIGHBOR (KNN)**"""

from sklearn.neighbors import KNeighborsClassifier
knn=KNeighborsClassifier()
knn.fit(x_train_scaled,y_train)

pred4=knn.predict(x_test_scaled)
pred4

from sklearn.metrics import accuracy_score
accuracy_score(y_test,pred4)

"""**MODEL 5: SUPPORT VECTOR CLASSIFIER (SVC)**"""

from sklearn.svm import SVC
svc=SVC()
svc.fit(x_train_scaled,y_train)

pred5=svc.predict(x_test_scaled)
pred5

from sklearn.metrics import accuracy_score
accuracy_score(y_test,pred5)

"""**MODEL 6: XGB CLASSIFIER**"""

import xgboost

from xgboost import XGBClassifier
xgb=XGBClassifier()
xgb.fit(x_train_scaled,y_train)

pred6=xgb.predict(x_test_scaled)
pred6

pred_df=pd.DataFrame(pred6)
pred_df

final_df=pd.concat([df,pred_df],axis=1)
final_df

from sklearn.metrics import accuracy_score
accuracy_score(y_test,pred6)

"""**COMPARING THE ACCURACIES OF ALL THE MODELS:**

Following are the accuracy scores of all the models-

Logistic regression:   79%

Decision tree:         92%

Random forest:         96%

KNN:                   87%

SVC:                   89%

XGB:                   96%

"""

model={'Model_Type':['Logistic_reg','Decision_tr','Random_for','KNN','SVC','XGB'],
       'Accuracy':[79,92,96,87,89,96]}
df1=pd.DataFrame(model)
df1

sns.barplot(x=df1['Model_Type'],y=df1['Accuracy'],color='purple')

"""**CONCLUSION:**

**From the above values we can clearly conclude that random forest classifier and XGB classifier are the best models for this project.**
"""